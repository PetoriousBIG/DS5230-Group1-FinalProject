{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voyY5fDTABju",
        "outputId": "6b29e2b9-9693-45df-8845-0ac8b6d05870"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install requests pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBnzC_ASX3DI",
        "outputId": "e6d0bc99-683a-4a00-c1b6-192da4b0a7d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.11/dist-packages (1.0.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from langdetect) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install langdetect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "BlS4tLvk_8on",
        "outputId": "2792d408-2a5f-4394-c379-c58cf0c93276"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error fetching data: 400 - {\"error\":\"Requested data for this limit and/or offset is not available\"}\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_497a8a42-0302-4de1-9675-af4865d95fe1\", \"Google Scholar AI&ML Papers.csv\", 14202915)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 10341,\n  \"fields\": [\n    {\n      \"column\": \"Title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9858,\n        \"samples\": [\n          \"MRI evaluation of small (<4cm) solid renal masses: multivariate modeling improves diagnostic accuracy for angiomyolipoma without visible fat compared to univariate analysis\",\n          \"GeoNet: Unsupervised Learning of Dense Depth, Optical Flow and Camera Pose\",\n          \"Adaptive Selective Ensemble-Independent Component Analysis Models for Process Monitoring\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Abstract\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7999,\n        \"samples\": [\n          \"High-resolution stellar spectra offer valuable insights into atmospheric parameters and chemical compositions. However, their inherent complexity and high-dimensionality present challenges in fully utilizing the information they contain. In this study, we utilize data from the Apache Point Observatory Galactic Evolution Experiment (APOGEE) within the Sloan Digital Sky Survey IV (SDSS-IV) to explore latent representations of chemical abundances by applying five dimensionality reduction techniques: PCA, t-SNE, UMAP, Autoencoder, and VAE. Through this exploration, we evaluate the preservation of information and compare reconstructed outputs with the original 19 chemical abundance data. Our findings reveal a performance ranking of PCA<UMAP<t-SNE<VAE<Autoencoder, through comparing their explained variance under optimized MSE. The performance of non-linear (Autoencoder and VAE) algorithms has approximately 10\\\\% improvement compared to linear (PCA) algorithm. This difference can be referred to as the\\\"non-linearity gap.\\\"Future work should focus on incorporating measurement errors into extension VAEs, thereby enhancing the reliability and interpretability of chemical abundance exploration in astronomical spectra.\",\n          \"Multivariate data such as spectra frequently contain measured variables that are uninformative, and removal of such variables requires the use of methods that can be used to select informative variables. Partial least squares (PLS) regression may incorporate information from uninformative measured variables, and so it is important to select variables before performing the PLS regression. Elastic net (EN) regression can be used to perform variable selection automatically. An EN regression can be used to select groups of correlated variables or to select either sparse or nonsparse sets of variables. However, the predictive performance of the EN regression can be significantly worse than competing 1\\u2010step variable selection methods such as variable importance in projection (VIP). In the present work, the use of the EN to select variables, followed by conventional PLS regression on the selected variables (EN\\u2010PLS), has been investigated. Variable selection by using EN\\u2010PLS was compared with that from EN regression, sparse PLS regression, VIP, and from selectivity ratio selection on 2 data sets of visible/near\\u2010infrared spectra. In all cases, the wavelengths selected were compared with reference data. The variables selected by using EN\\u2010PLS offered advantages in interpretability and gave more robust prediction performance as compared with those obtained from full\\u2010spectrum PLS and the other variable selection methods. This paper reports a method for variable selection by using an EN regression prior to a second regression by using PLS, a 2\\u2010step method termed EN\\u2010PLS. Variables selected by using EN\\u2010PLS are compared with variables selected from the EN regression, as well as VIP, selectivity ratio, and the sparse PLS regression, 3 commonly used methods for variable selection in chemometrics. The EN\\u2010PLS is shown to select variables that were more easily interpreted. In addition, EN\\u2010PLS performed more robustly than a PLS regression performed on all variables, as well as reduced PLS regressions by using variables selected from either the sparse PLS regression algorithm or a VIP variable selection followed by PLS modeling.\",\n          \"Abstract This paper proposes an integrated computational intelligence model called PANK for financial time series prediction. A PANK model consists of three parts: 1) Principal Component Analysis (PCA) for reducing redundancy information, 2) Affinity Propagation Clustering (AP) for generating exemplars and corresponding clusters as feature extraction, and 3) a nested reformulation of k-Nearest Neighbor regression (Nested KNN) for prediction modeling. The model captures training and testing data with a sliding window, uses PCA to reduce the redundancy information of historical data set and generates information-rich principal components which are input to AP for clustering, and applies Nested KNN to transform the clusters into output as prediction. In this paper, we advance the original KNN to a new Nested KNN which can tackle the large amount of computation and disequilibrium samples problem of original KNN. A specific PANK model is constructed and tested on Chinese stock index with 15-year historical data set, achieving best hit rate of 0.80.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Authors\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9661,\n        \"samples\": [\n          \"Minh Tu Hoang, Brosnan Yuen, Xiaodai Dong, Tao Lu, Robert Westendorp, K. Reddy\",\n          \"Majid Nawaz, Muhammad Inayatullah Khan Babar\",\n          \"Divya Thakur, Praveen Lalwani\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 2005,\n        \"max\": 2025,\n        \"num_unique_values\": 21,\n        \"samples\": [\n          2019,\n          2005,\n          2009\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"URL\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9899,\n        \"samples\": [\n          \"https://www.semanticscholar.org/paper/e2584492fb1c7b8e56abebe0f85d7145784e5f78\",\n          \"https://www.semanticscholar.org/paper/09fa73e0972412680bffb1ba6aac543b0a328927\",\n          \"https://www.semanticscholar.org/paper/78d89d7bec2359dd1bf29d011d3061bf9395883e\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Citations\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3840,\n        \"min\": 0,\n        \"max\": 187289,\n        \"num_unique_values\": 1418,\n        \"samples\": [\n          97,\n          144,\n          674\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Journal\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3148,\n        \"samples\": [\n          \"AQUA \\u2014 Water Infrastructure, Ecosystems and Society\",\n          \"Journal of Soft Computing Paradigm\",\n          \"2015 IEEE International Conference on Progress in Informatics and Computing (PIC)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Venue\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2887,\n        \"samples\": [\n          \"Journal of Electrical Systems\",\n          \"AIP Conference Proceedings\",\n          \"SC Workshops\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Publication Types\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 39,\n        \"samples\": [\n          \"MetaAnalysis, JournalArticle\",\n          \"Study, JournalArticle, ClinicalTrial\",\n          \"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-c22b74b3-e46b-4f70-821c-c246a95bc875\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Abstract</th>\n",
              "      <th>Authors</th>\n",
              "      <th>Year</th>\n",
              "      <th>URL</th>\n",
              "      <th>Citations</th>\n",
              "      <th>Journal</th>\n",
              "      <th>Venue</th>\n",
              "      <th>Publication Types</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>High-performance medicine: the convergence of ...</td>\n",
              "      <td>N/A</td>\n",
              "      <td>E. Topol</td>\n",
              "      <td>2019</td>\n",
              "      <td>https://www.semanticscholar.org/paper/f134abea...</td>\n",
              "      <td>4135</td>\n",
              "      <td>Nature Medicine</td>\n",
              "      <td>Nature Network Boston</td>\n",
              "      <td>Review, JournalArticle</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Explainable Artificial Intelligence (XAI): Con...</td>\n",
              "      <td>N/A</td>\n",
              "      <td>Alejandro Barredo Arrieta, Natalia Díaz Rodríg...</td>\n",
              "      <td>2019</td>\n",
              "      <td>https://www.semanticscholar.org/paper/530a059c...</td>\n",
              "      <td>5944</td>\n",
              "      <td>Inf. Fusion</td>\n",
              "      <td>Information Fusion</td>\n",
              "      <td>JournalArticle, Review</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Explanation in Artificial Intelligence: Insigh...</td>\n",
              "      <td>N/A</td>\n",
              "      <td>Tim Miller</td>\n",
              "      <td>2017</td>\n",
              "      <td>https://www.semanticscholar.org/paper/e89dfa30...</td>\n",
              "      <td>4120</td>\n",
              "      <td>Artif. Intell.</td>\n",
              "      <td>Artificial Intelligence</td>\n",
              "      <td>JournalArticle, Review</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sparks of Artificial General Intelligence: Ear...</td>\n",
              "      <td>Artificial intelligence (AI) researchers have ...</td>\n",
              "      <td>Sébastien Bubeck, Varun Chandrasekaran, Ronen ...</td>\n",
              "      <td>2023</td>\n",
              "      <td>https://www.semanticscholar.org/paper/8dbd5746...</td>\n",
              "      <td>2854</td>\n",
              "      <td>ArXiv</td>\n",
              "      <td>arXiv.org</td>\n",
              "      <td>JournalArticle</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Peeking Inside the Black-Box: A Survey on Expl...</td>\n",
              "      <td>At the dawn of the fourth industrial revolutio...</td>\n",
              "      <td>Amina Adadi, M. Berrada</td>\n",
              "      <td>2018</td>\n",
              "      <td>https://www.semanticscholar.org/paper/21dff47a...</td>\n",
              "      <td>3709</td>\n",
              "      <td>IEEE Access</td>\n",
              "      <td>IEEE Access</td>\n",
              "      <td>JournalArticle, Review</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c22b74b3-e46b-4f70-821c-c246a95bc875')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c22b74b3-e46b-4f70-821c-c246a95bc875 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c22b74b3-e46b-4f70-821c-c246a95bc875');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-c26181e1-6330-4ff3-8bca-ac7afc9c1fdf\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c26181e1-6330-4ff3-8bca-ac7afc9c1fdf')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-c26181e1-6330-4ff3-8bca-ac7afc9c1fdf button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                               Title  \\\n",
              "0  High-performance medicine: the convergence of ...   \n",
              "1  Explainable Artificial Intelligence (XAI): Con...   \n",
              "2  Explanation in Artificial Intelligence: Insigh...   \n",
              "3  Sparks of Artificial General Intelligence: Ear...   \n",
              "4  Peeking Inside the Black-Box: A Survey on Expl...   \n",
              "\n",
              "                                            Abstract  \\\n",
              "0                                                N/A   \n",
              "1                                                N/A   \n",
              "2                                                N/A   \n",
              "3  Artificial intelligence (AI) researchers have ...   \n",
              "4  At the dawn of the fourth industrial revolutio...   \n",
              "\n",
              "                                             Authors  Year  \\\n",
              "0                                           E. Topol  2019   \n",
              "1  Alejandro Barredo Arrieta, Natalia Díaz Rodríg...  2019   \n",
              "2                                         Tim Miller  2017   \n",
              "3  Sébastien Bubeck, Varun Chandrasekaran, Ronen ...  2023   \n",
              "4                            Amina Adadi, M. Berrada  2018   \n",
              "\n",
              "                                                 URL  Citations  \\\n",
              "0  https://www.semanticscholar.org/paper/f134abea...       4135   \n",
              "1  https://www.semanticscholar.org/paper/530a059c...       5944   \n",
              "2  https://www.semanticscholar.org/paper/e89dfa30...       4120   \n",
              "3  https://www.semanticscholar.org/paper/8dbd5746...       2854   \n",
              "4  https://www.semanticscholar.org/paper/21dff47a...       3709   \n",
              "\n",
              "           Journal                    Venue       Publication Types  \n",
              "0  Nature Medicine    Nature Network Boston  Review, JournalArticle  \n",
              "1      Inf. Fusion       Information Fusion  JournalArticle, Review  \n",
              "2   Artif. Intell.  Artificial Intelligence  JournalArticle, Review  \n",
              "3            ArXiv                arXiv.org          JournalArticle  \n",
              "4      IEEE Access              IEEE Access  JournalArticle, Review  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import time  # For handling API rate limits\n",
        "import os\n",
        "from google.colab import files\n",
        "from datetime import datetime\n",
        "from langdetect import detect, LangDetectException # detect = language identifier, LangDetectException = error if detection fails\n",
        "\n",
        "# Load API key from an environment variable for security\n",
        "SS_API = os.getenv(\"SEMANTIC_SCHOLAR_API_KEY\", \"Insert Sematic Scholar API Key\")\n",
        "\n",
        "# Get the current year and define the past 20 years range\n",
        "current = datetime.now().year  # Get the current year\n",
        "start = current- 20  # Define the start year as 20 years ago\n",
        "\n",
        "# Function to fetch AI/ML research papers from Semantic Scholar with pagination\n",
        "def googleScholar(query, max_results=1000):  # Allows fetching up to 1000 results per query\n",
        "    url = \"https://api.semanticscholar.org/graph/v1/paper/search\"  # API endpoint\n",
        "    headers = {\"x-api-key\": SS_API}  # API authentication header as it mentioned by API provider\n",
        "\n",
        "    papers = []  # store paper list\n",
        "    total_fetched = 0  # Counter\n",
        "    offset = 0  # Track offset\n",
        "\n",
        "    # Loop until we fetch the required number of results\n",
        "    while total_fetched < max_results:\n",
        "        params = {\n",
        "            \"query\": query,  # Search query term\n",
        "            \"limit\": min(100, max_results - total_fetched),  # Fetch up to 100 at a time (Predefined max number by Google)\n",
        "            \"offset\": offset,  # offset to fetch next batch of results\n",
        "            \"fields\": \"title,abstract,authors,year,url,citationCount,journal,venue,publicationTypes\", # Lables of dataset\n",
        "            \"year\": f\"{start}-{current}\"  # Fetch only from the last 20 years\n",
        "        }\n",
        "\n",
        "        response = requests.get(url, headers=headers, params=params)  # Make API request\n",
        "\n",
        "        # Handle API rate limits and errors with exponential backoff\n",
        "        if response.status_code == 429:  # If API rate limit is exceeded\n",
        "            wait_time = 2  # Initial wait time in seconds\n",
        "            while response.status_code == 429:  # Keep retrying until allowed\n",
        "                print(f\"Rate limit exceeded. Waiting for {wait_time} seconds...\")\n",
        "                time.sleep(wait_time)  # Wait before retrying\n",
        "                wait_time *= 2  # Increase wait time (exponential backoff)\n",
        "                response = requests.get(url, headers=headers, params=params)  # Retry API request\n",
        "\n",
        "        elif response.status_code != 200:  # Handle other errors\n",
        "            print(f\"Error fetching data: {response.status_code} - {response.text}\")\n",
        "            break  # Stop execution on API error\n",
        "\n",
        "        data = response.json()  # Convert API response to JSON format\n",
        "        papers_fetched = data.get(\"data\", [])  # Extract paper data from response\n",
        "\n",
        "        # If no more results, stop fetching\n",
        "        if not papers_fetched:\n",
        "            print(f\"No more results for query: {query}\")\n",
        "            break\n",
        "\n",
        "        for paper in papers_fetched:\n",
        "            year = paper.get(\"year\", 0)\n",
        "            if start <= year <= current:\n",
        "               title = paper.get(\"title\", \"\")\n",
        "               abstract = paper.get(\"abstract\", \"\")\n",
        "\n",
        "            try:\n",
        "               if detect(title) != \"en\":\n",
        "                    continue\n",
        "               if abstract and detect(abstract) != \"en\":\n",
        "                continue\n",
        "            except LangDetectException:\n",
        "                continue  # skip if language detection fails\n",
        "\n",
        "            papers.append({\n",
        "                \"Title\": title or \"N/A\",\n",
        "                \"Abstract\": abstract or \"N/A\",\n",
        "                \"Authors\": \", \".join([author[\"name\"] for author in paper.get(\"authors\", [])]),\n",
        "                \"Year\": year,\n",
        "                \"URL\": paper.get(\"url\", \"N/A\"),\n",
        "                \"Citations\": paper.get(\"citationCount\", \"N/A\"),\n",
        "                \"Journal\": (paper.get(\"journal\") or {}).get(\"name\", \"N/A\"),\n",
        "                \"Venue\": paper.get(\"venue\", \"N/A\"),\n",
        "                \"Publication Types\": \", \".join(paper.get(\"publicationTypes\", []) or [])\n",
        "            })\n",
        "\n",
        "        total_fetched += len(papers_fetched)  # Update the total fetched count\n",
        "        offset += len(papers_fetched)  # Move the offset forward\n",
        "\n",
        "        # Respect API rate limits by adding a small delay\n",
        "        time.sleep(1)\n",
        "\n",
        "    return papers  # Return the list of fetched papers\n",
        "\n",
        "# List of queries to fetch AI & ML research papers\n",
        "queries = [\n",
        "    # General AI & ML\n",
        "    \"artificial intelligence\",\n",
        "    \"machine learning\",\n",
        "    \"deep learning\",\n",
        "    \"reinforcement learning\",\n",
        "    \"supervised learning\",\n",
        "    \"unsupervised learning\",\n",
        "    \"semi-supervised learning\",\n",
        "    \"self-supervised learning\",\n",
        "    \"neural networks\",\n",
        "    \"transformer models\",\n",
        "    \"generative AI\",\n",
        "    \"AI applications\",\n",
        "    \"AI in healthcare\",\n",
        "    \"AI in finance\",\n",
        "    \"AI in robotics\",\n",
        "    \"AI in education\",\n",
        "    \"machine learning algorithms\",\n",
        "    \"automated machine learning\",\n",
        "    \"AI ethics\",\n",
        "    \"explainable AI\",\n",
        "    \"AI safety\",\n",
        "    \"AI governance\",\n",
        "\n",
        "    # Core Algorithms & Techniques\n",
        "    # Supervised\n",
        "    \"linear regression\",\n",
        "    \"logistic regression\",\n",
        "    \"decision trees\",\n",
        "    \"random forest classifier\",\n",
        "    \"support vector machines\",\n",
        "    \"naive Bayes classifier\",\n",
        "    \"k-nearest neighbors classifier\",\n",
        "    \"gradient boosting machines\",\n",
        "    \"XGBoost classifier\",\n",
        "    \"LightGBM classifier\",\n",
        "    \"CatBoost classifier\",\n",
        "    \"ridge regression\",\n",
        "    \"lasso regression\",\n",
        "    \"elastic net regression\",\n",
        "    \"multi-class classification\",\n",
        "    \"ordinal regression\",\n",
        "    \"ensemble methods in machine learning\",\n",
        "    \"stacking ensemble learning\",\n",
        "    \"bagging and boosting\",\n",
        "    \"regression trees\",\n",
        "    \"classification algorithms\",\n",
        "    \"cross-validation techniques\",\n",
        "\n",
        "    # Unsupervised\n",
        "    \"k-means clustering\",\n",
        "    \"hierarchical clustering\",\n",
        "    \"density-based clustering\",\n",
        "    \"DBSCAN algorithm\",\n",
        "    \"Gaussian mixture models\",\n",
        "    \"mean shift clustering\",\n",
        "    \"spectral clustering\",\n",
        "    \"affinity propagation\",\n",
        "    \"self-organizing maps\",\n",
        "    \"principal component analysis PCA\",\n",
        "    \"independent component analysis ICA\",\n",
        "    \"t-SNE visualization\",\n",
        "    \"UMAP dimensionality reduction\",\n",
        "    \"autoencoders for representation learning\",\n",
        "    \"deep clustering methods\",\n",
        "    \"latent Dirichlet allocation LDA\",\n",
        "    \"topic modeling\",\n",
        "    \"anomaly detection\",\n",
        "    \"outlier detection algorithms\",\n",
        "\n",
        "    # Deep Learning & Neural Architectures\n",
        "    \"convolutional neural networks\",\n",
        "    \"recurrent neural networks\",\n",
        "    \"long short-term memory\",\n",
        "    \"transformers\",\n",
        "    \"attention mechanisms\",\n",
        "    \"vision transformers\",\n",
        "    \"GANs generative adversarial networks\",\n",
        "    \"BERT model\",\n",
        "    \"GPT models\",\n",
        "    \"diffusion models\",\n",
        "    \"multi-modal learning\",\n",
        "    \"zero-shot learning\",\n",
        "    \"few-shot learning\",\n",
        "    \"meta learning\",\n",
        "    \"neural architecture search\",\n",
        "\n",
        "    # Libraries & Frameworks\n",
        "    \"TensorFlow machine learning\",\n",
        "    \"PyTorch deep learning\",\n",
        "    \"Scikit-learn algorithms\",\n",
        "    \"Keras deep learning\",\n",
        "    \"Hugging Face transformers\",\n",
        "    \"JAX ML library\",\n",
        "    \"ONNX AI models\",\n",
        "\n",
        "    # Evaluation, Fairness, and Interpretability\n",
        "    \"model evaluation in machine learning\",\n",
        "    \"model interpretability\",\n",
        "    \"model explainability\",\n",
        "    \"fairness in machine learning\",\n",
        "    \"bias in AI models\",\n",
        "    \"AUC ROC evaluation\",\n",
        "    \"precision recall tradeoff\",\n",
        "    \"SHAP values\",\n",
        "    \"LIME explainability\",\n",
        "\n",
        "    # AI Research Topics & Trends\n",
        "    \"foundation models\",\n",
        "    \"large language models\",\n",
        "    \"AI and climate change\",\n",
        "    \"AI for social good\",\n",
        "    \"neurosymbolic AI\",\n",
        "    \"human-in-the-loop learning\",\n",
        "    \"online learning\",\n",
        "    \"continual learning\",\n",
        "    \"federated learning\",\n",
        "    \"privacy preserving machine learning\",\n",
        "    \"causal inference in ML\",\n",
        "    \"contrastive learning\",\n",
        "    \"representation learning\"\n",
        "]\n",
        "\n",
        "\n",
        "all_papers = []  # List to store papers from all queries\n",
        "\n",
        "# Loop through each query and fetch research papers\n",
        "for query in queries:\n",
        "    papers = googleScholar(query, max_results=1000)  # Fetch papers for the given query\n",
        "    all_papers.extend(papers)  # Append fetched papers to the main list\n",
        "\n",
        "# Convert fetched data to a Pandas DataFrame\n",
        "df = pd.DataFrame(all_papers)\n",
        "\n",
        "# Save data as a CSV file\n",
        "file_name = \"Google Scholar AI&ML Papers.csv\"\n",
        "df.to_csv(file_name, index=False)\n",
        "\n",
        "# Download the file if user use Google Colab to run the code. Otherwise, will be downloaded at the root\n",
        "files.download(file_name)\n",
        "\n",
        "df.head()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "myenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
