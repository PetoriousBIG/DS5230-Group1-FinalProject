{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hdb0X28Vd1mz",
        "outputId": "6cb309a5-f8ff-4a2c-a1be-c0d460c75f0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (4.13.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install requests beautifulsoup4 pandas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "_is3YyTUdyYa",
        "outputId": "53a5274d-7a50-405f-bb9f-cb1e92ab61da"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "from time import sleep\n",
        "from datetime import datetime\n",
        "import random\n",
        "from google.colab import files\n",
        "\n",
        "key = \"Insert Google API\"\n",
        "search_url = \"https://www.googleapis.com/youtube/v3/search\"\n",
        "video_url = \"https://www.googleapis.com/youtube/v3/videos\"\n",
        "\n",
        "# List of queries\n",
        "queries = [\n",
        "    # General AI & ML\n",
        "    \"artificial intelligence\",\n",
        "    \"machine learning\",\n",
        "    \"deep learning\",\n",
        "    \"reinforcement learning\",\n",
        "    \"supervised learning\",\n",
        "    \"unsupervised learning\",\n",
        "    \"semi-supervised learning\",\n",
        "    \"self-supervised learning\",\n",
        "    \"neural networks\",\n",
        "    \"transformer models\",\n",
        "    \"generative AI\",\n",
        "    \"AI applications\",\n",
        "    \"AI in healthcare\",\n",
        "    \"AI in finance\",\n",
        "    \"AI in robotics\",\n",
        "    \"AI in education\",\n",
        "    \"machine learning algorithms\",\n",
        "    \"automated machine learning\",\n",
        "    \"AI ethics\",\n",
        "    \"explainable AI\",\n",
        "    \"AI safety\",\n",
        "    \"AI governance\",\n",
        "\n",
        "    # Core Algorithms & Techniques\n",
        "    # Supervised\n",
        "    \"linear regression\",\n",
        "    \"logistic regression\",\n",
        "    \"decision trees\",\n",
        "    \"random forest classifier\",\n",
        "    \"support vector machines\",\n",
        "    \"naive Bayes classifier\",\n",
        "    \"k-nearest neighbors classifier\",\n",
        "    \"gradient boosting machines\",\n",
        "    \"XGBoost classifier\",\n",
        "    \"LightGBM classifier\",\n",
        "    \"CatBoost classifier\",\n",
        "    \"ridge regression\",\n",
        "    \"lasso regression\",\n",
        "    \"elastic net regression\",\n",
        "    \"multi-class classification\",\n",
        "    \"ordinal regression\",\n",
        "    \"ensemble methods in machine learning\",\n",
        "    \"stacking ensemble learning\",\n",
        "    \"bagging and boosting\",\n",
        "    \"regression trees\",\n",
        "    \"classification algorithms\",\n",
        "    \"cross-validation techniques\",\n",
        "\n",
        "    # Unsupervised\n",
        "    \"k-means clustering\",\n",
        "    \"hierarchical clustering\",\n",
        "    \"density-based clustering\",\n",
        "    \"DBSCAN algorithm\",\n",
        "    \"Gaussian mixture models\",\n",
        "    \"mean shift clustering\",\n",
        "    \"spectral clustering\",\n",
        "    \"affinity propagation\",\n",
        "    \"self-organizing maps\",\n",
        "    \"principal component analysis PCA\",\n",
        "    \"independent component analysis ICA\",\n",
        "    \"t-SNE visualization\",\n",
        "    \"UMAP dimensionality reduction\",\n",
        "    \"autoencoders for representation learning\",\n",
        "    \"deep clustering methods\",\n",
        "    \"latent Dirichlet allocation LDA\",\n",
        "    \"topic modeling\",\n",
        "    \"anomaly detection\",\n",
        "    \"outlier detection algorithms\",\n",
        "\n",
        "    # Deep Learning & Neural Architectures\n",
        "    \"convolutional neural networks\",\n",
        "    \"recurrent neural networks\",\n",
        "    \"long short-term memory\",\n",
        "    \"transformers\",\n",
        "    \"attention mechanisms\",\n",
        "    \"vision transformers\",\n",
        "    \"GANs generative adversarial networks\",\n",
        "    \"BERT model\",\n",
        "    \"GPT models\",\n",
        "    \"diffusion models\",\n",
        "    \"multi-modal learning\",\n",
        "    \"zero-shot learning\",\n",
        "    \"few-shot learning\",\n",
        "    \"meta learning\",\n",
        "    \"neural architecture search\",\n",
        "\n",
        "    # Libraries & Frameworks\n",
        "    \"TensorFlow machine learning\",\n",
        "    \"PyTorch deep learning\",\n",
        "    \"Scikit-learn algorithms\",\n",
        "    \"Keras deep learning\",\n",
        "    \"Hugging Face transformers\",\n",
        "    \"JAX ML library\",\n",
        "    \"ONNX AI models\",\n",
        "\n",
        "    # Evaluation, Fairness, and Interpretability\n",
        "    \"model evaluation in machine learning\",\n",
        "    \"model interpretability\",\n",
        "    \"model explainability\",\n",
        "    \"fairness in machine learning\",\n",
        "    \"bias in AI models\",\n",
        "    \"AUC ROC evaluation\",\n",
        "    \"precision recall tradeoff\",\n",
        "    \"SHAP values\",\n",
        "    \"LIME explainability\",\n",
        "\n",
        "    # AI Research Topics & Trends\n",
        "    \"foundation models\",\n",
        "    \"large language models\",\n",
        "    \"AI and climate change\",\n",
        "    \"AI for social good\",\n",
        "    \"neurosymbolic AI\",\n",
        "    \"human-in-the-loop learning\",\n",
        "    \"online learning\",\n",
        "    \"continual learning\",\n",
        "    \"federated learning\",\n",
        "    \"privacy preserving machine learning\",\n",
        "    \"causal inference in ML\",\n",
        "    \"contrastive learning\",\n",
        "    \"representation learning\"\n",
        "]\n",
        "\n",
        "def fetch_video(video_ids):\n",
        "    \"\"\"Fetch extra details about videos using the Videos endpoint\"\"\"\n",
        "    params = {\n",
        "        \"part\": \"snippet,contentDetails,statistics\",\n",
        "        \"id\": \",\".join(video_ids),\n",
        "        \"key\": key\n",
        "    }\n",
        "    response = requests.get(video_url, params=params)\n",
        "    response.raise_for_status()\n",
        "    return response.json()[\"items\"]\n",
        "\n",
        "def scrape_youtube(query):\n",
        "    params = {\n",
        "        \"part\": \"snippet\",\n",
        "        \"q\": query,\n",
        "        \"type\": \"video\",\n",
        "        \"maxResults\": 10,\n",
        "        \"key\": key\n",
        "    }\n",
        "    response = requests.get(search_url, params=params)\n",
        "    response.raise_for_status()\n",
        "    search_results = response.json()[\"items\"]\n",
        "\n",
        "    video_ids = [item[\"id\"][\"videoId\"] for item in search_results]\n",
        "    video_details = fetch_video(video_ids)\n",
        "\n",
        "    results = []\n",
        "    for video in video_details:\n",
        "        results.append({\n",
        "            \"query\": query,\n",
        "            \"video_id\": video[\"id\"],\n",
        "            \"title\": video[\"snippet\"][\"title\"],\n",
        "            \"channel\": video[\"snippet\"][\"channelTitle\"],\n",
        "            \"publish_date\": video[\"snippet\"][\"publishedAt\"],\n",
        "            \"duration\": video[\"contentDetails\"][\"duration\"],\n",
        "            \"views\": video.get(\"statistics\", {}).get(\"viewCount\", \"N/A\"),\n",
        "            \"url\": f\"https://www.youtube.com/watch?v={video['id']}\",\n",
        "            \"timestamp_scraped\": datetime.now().isoformat()\n",
        "        })\n",
        "\n",
        "    return results\n",
        "\n",
        "# Collect results for all queries\n",
        "all_results = []\n",
        "for q in queries:\n",
        "    try:\n",
        "        all_results.extend(scrape_youtube(q))\n",
        "    except Exception as e:\n",
        "        print(f\"Error with query '{q}': {e}\")\n",
        "    sleep(random.uniform(1.5, 3.0))  # Random sleep to avoid runtime error from youtube\n",
        "\n",
        "# Remove duplicates (by video_id)\n",
        "df = pd.DataFrame(all_results).drop_duplicates(subset=\"video_id\")\n",
        "\n",
        "# Save to file with timestamp\n",
        "file = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "file_name = f\"youtube AI&ML {file}.csv\"\n",
        "df.to_csv(file_name, index=False)\n",
        "\n",
        "# For Google Colab users\n",
        "try:\n",
        "    files.download(file_name)\n",
        "except ImportError:\n",
        "    print(f\"CSV file saved locally as {file_name}.\")\n",
        "\n",
        "df.head()\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
